import os
from dotenv import load_dotenv
import requests
import urllib.parse
from bs4 import BeautifulSoup
import pandas as pd
import time
import re
import mysql.connector

#   id integer [primary key]                   ==> index    (0ë¶€í„° ì‹œì‘)
#   title varchar // ë‰´ìŠ¤ ì œëª©                  ==> title
#   link varchar // ë‰´ìŠ¤ ì›ë³¸ ë§í¬               ==> url
#   upload_date timestamp // ë‰´ìŠ¤ ì—…ë°ì´íŠ¸ ê¸°ì‚¬   ==> upload_date
#   photo_link varchar // ë‰´ìŠ¤ ì‚¬ì§„ ë§í¬         ==> thumbnail
#   press_id integer // ì–¸ë¡ ì‚¬                  ==> company
#   category_id integer // ì¹´í…Œê³ ë¦¬ ID           ==> subject
#   topic_id integer // ìš”ì•½ ID                 ==> cluster2nd

# load .env
load_dotenv()

# ğŸ”§ ë„¤ì´ë²„ API ì¸ì¦ ì •ë³´
client_id = os.environ.get('NAVER_CLIENT_ID')
client_secret = os.environ.get('NAVER_KEY')

# ğŸ” ê²€ìƒ‰ì–´ ì„¤ì •
query = 'AI ë‰´ìŠ¤'
enc_query = urllib.parse.quote(query)

# ğŸ“¦ ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸
news_data = []

# ğŸ“° ë‰´ìŠ¤ ë³¸ë¬¸ í¬ë¡¤ë§ í•¨ìˆ˜
def get_news_body(link):
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        res = requests.get(link, headers=headers, timeout=5)
        if res.status_code != 200:
            return f"[{res.status_code}] ì ‘ê·¼ ì‹¤íŒ¨"
        soup = BeautifulSoup(res.text, 'html.parser')

        article = soup.select_one('#dic_area') or soup.select_one('.newsct_article')
        if article:
            return article.get_text(strip=True)

        paragraphs = soup.find_all('p')
        if paragraphs:
            return ' '.join(p.get_text(strip=True) for p in paragraphs[:5])
        return "[ë³¸ë¬¸ ì—†ìŒ]"
    except Exception as e:
        return f"[ì—ëŸ¬] {e}"

# ğŸ–¼ ì¸ë„¤ì¼ ì´ë¯¸ì§€ ì£¼ì†Œ ì¶”ì¶œ í•¨ìˆ˜
def get_news_thumbnail(link):
    headers = {'User-Agent': 'Mozilla/5.0'}
    img_tag = []
    try:
        res = requests.get(link, headers=headers, timeout=5)
        if res.status_code != 200:
            return ""
        soup = BeautifulSoup(res.text, 'html.parser')

        # 1ìˆœìœ„: id="img1"
        img_tag = soup.find('img', id='img1')
        if img_tag and img_tag.get('src'):
            return img_tag['data-src']

        # 2ìˆœìœ„: classë¡œ 'ëŒ€í‘œ ì´ë¯¸ì§€' ì¶”ì •
        # img_tag = soup.find('img', class_='_LAZY_LOADING _LAZY_LOADING_INIT_HIDE')  # ë„¤ì´ë²„ ë‰´ìŠ¤ ëŒ€í‘œ ì´ë¯¸ì§€ class ìì£¼ ì‚¬ìš©ë¨
        # if img_tag and img_tag.get('src'):
        #     return img_tag['data-src']

        # 3ìˆœìœ„: ê°€ì¥ ì²« ë²ˆì§¸ <img> íƒœê·¸ (ë‹¨, ê´‘ê³  í•„í„°ë§ í•„ìš”í•  ìˆ˜ ìˆìŒ)
        # img_tag = soup.find('img')
        # if img_tag and img_tag.get('src'):
        #     return img_tag['src']

        print(img_tag['data-src'])
        return img_tag['data-src']
    except Exception as e:
        print(e)
        return ""

# ì–¸ë¡ ì‚¬ ì¶”ì¶œ í•¨ìˆ˜
def get_news_company(link):
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        res = requests.get(link, headers=headers, timeout=5)
        if res.status_code != 200:
            return ""
        soup = BeautifulSoup(res.text, 'html.parser')

        # ì–¸ë¡ ì‚¬ ë¡œê³  ì´ë¯¸ì§€ì—ì„œ title ì†ì„± ì¶”ì¶œ
        logo_img = soup.find('img', class_='media_end_head_top_logo_img')
        if logo_img and logo_img.get('title'):
            return logo_img['title'].strip()

        return ""
    except Exception:
        return ""

def get_news_subject(link):
    try:
        match = re.search(r"sid=(\d+)", link)
        if match:
            return match.group(1)
        else:
            return ""
    except:
        return ""


# ğŸ” API í˜¸ì¶œ ë° ë°ì´í„° ìˆ˜ì§‘
for i in range(100):
    start_index = i * 10 + 1
    url = f"https://openapi.naver.com/v1/search/news.json?query={enc_query}&display=10&start={start_index}&sort=date"

    print(f"ğŸš€ {i+1}ë²ˆì§¸ ìš”ì²­ (ì‹œì‘ ì¸ë±ìŠ¤: {start_index})")
    headers = {
        "X-Naver-Client-Id": client_id,
        "X-Naver-Client-Secret": client_secret
    }

    response = requests.get(url, headers=headers)

    if response.status_code == 200:
        news_items = response.json()['items']
        for item in news_items:
            title = item['title'].replace('<b>', '').replace('</b>', '')
            link = item['link']
            upload_date = item['pubDate']

            if 'n.news.naver.com' not in link:
                # print(f"   [SKIP] ë„¤ì´ë²„ ë‰´ìŠ¤ ë§í¬ê°€ ì•„ë‹™ë‹ˆë‹¤: {link}")
                continue

            content = get_news_body(link)
            thumbnail = get_news_thumbnail(link)
            company = get_news_company(link)
            subject = get_news_subject(link)
            #upload_date = get_upload_date(link)


            news_data.append({
                'title': title,
                'url': link,
                'contents': content,
                'thumbnail': thumbnail,
                'company': company,
                'subject': subject,
                'upload_date': upload_date
            })
    else:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {response.status_code} - {response.text}")
        break

    time.sleep(0.5)

# ğŸ“„ DataFrameìœ¼ë¡œ ì €ì¥í•˜ê³  ì—‘ì…€ë¡œ ì¶œë ¥
print("\në°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ! ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤...")
df = pd.DataFrame(news_data)
df.to_excel("/app/data/news_1000_results.xlsx", index=False)
print(f"âœ… ì´ {len(df)}ê°œì˜ ë‰´ìŠ¤ë¥¼ '/app/data/news_1000_results.xlsx'ë¡œ ì €ì¥ ì™„ë£Œ!")


########## DB ############

# KUBERNETES_SERVICE_HOST í™˜ê²½ ë³€ìˆ˜ê°€ ì •ì˜ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´
# 'backend/.env' íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
# Docker í™˜ê²½ì—ì„œëŠ” ì´ ë³€ìˆ˜ê°€ ì •ì˜ë  ê°€ëŠ¥ì„±ì´ ë†’ìœ¼ë¯€ë¡œ, ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œ ìœ ìš©í•©ë‹ˆë‹¤.
if os.environ.get("KUBERNETES_SERVICE_HOST") is None:
    # .env íŒŒì¼ì˜ ê²½ë¡œë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•©ë‹ˆë‹¤.
    # í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë”°ë¼ 'backend/.env' ëŒ€ì‹  '.env'ë§Œ í•„ìš”í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
    # ì˜ˆ: load_dotenv(dotenv_path=".env")
    load_dotenv(dotenv_path=".env")

# MySQL ì—°ê²° ì„¤ì •
# í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ .get() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ê³  ê¸°ë³¸ê°’ì„ ì œê³µí•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
try:
    conn = mysql.connector.connect(
        host=os.environ.get("DB_HOST", "localhost"), # í™˜ê²½ ë³€ìˆ˜ ì—†ìœ¼ë©´ 'localhost' ê¸°ë³¸ê°’
        user=os.environ.get("DB_USER", "root"),       # í™˜ê²½ ë³€ìˆ˜ ì—†ìœ¼ë©´ 'root' ê¸°ë³¸ê°’
        password=os.environ.get("DB_PASSWORD", ""),   # í™˜ê²½ ë³€ìˆ˜ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ê¸°ë³¸ê°’
        database=os.environ.get("DB_NAME", "test_db"), # í™˜ê²½ ë³€ìˆ˜ ì—†ìœ¼ë©´ 'test_db' ê¸°ë³¸ê°’
    )
    cursor = conn.cursor()
    print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ!")
except mysql.connector.Error as err:
    print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {err}")
    # ì˜¤ë¥˜ ë°œìƒ ì‹œ í”„ë¡œê·¸ë¨ ì¢…ë£Œ ë˜ëŠ” ì ì ˆí•œ ì˜ˆì™¸ ì²˜ë¦¬
    exit()

# news_raw í…Œì´ë¸” ìƒì„± (ì—†ì„ ê²½ìš°)
create_table_sql = """
CREATE TABLE IF NOT EXISTS news_raw (
    id INT AUTO_INCREMENT PRIMARY KEY,
    title TEXT,
    url VARCHAR(767) UNIQUE, -- UNIQUE ì¸ë±ìŠ¤ ì¶”ê°€ (TEXT íƒ€ì…ì— ì§ì ‘ ì¸ë±ìŠ¤ ë¶ˆê°€, VARCHAR ê¸¸ì´ ì œí•œ)
    contents LONGTEXT,       -- LONGTEXTë¡œ ë³€ê²½
    thumbnail TEXT,
    company VARCHAR(100),
    subject VARCHAR(10),
    upload_date DATETIME
);
"""
try:
    cursor.execute(create_table_sql)
    conn.commit()
    print("âœ… 'news_raw' í…Œì´ë¸” í™•ì¸/ìƒì„± ì™„ë£Œ!")
except mysql.connector.Error as err:
    print(f"âŒ í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {err}")
    exit()

# INSERT ì¿¼ë¦¬
insert_sql = """
INSERT INTO news_raw (title, url, contents, thumbnail, company, subject, upload_date)
VALUES (%s, %s, %s, %s, %s, %s, %s)
ON DUPLICATE KEY UPDATE
    title = VALUES(title),
    contents = VALUES(contents),
    thumbnail = VALUES(thumbnail),
    company = VALUES(company),
    subject = VALUES(subject),
    upload_date = VALUES(upload_date)
"""

for news in news_data:
    try:
        cursor.execute(insert_sql, (
            news['title'],
            news['url'],
            news['contents'],
            news['thumbnail'],
            news['company'],
            news['subject'],
            pd.to_datetime(news['upload_date'])  # pubDate ë¬¸ìì—´ â†’ datetime ë³€í™˜
        ))
    except Exception as e:
        print("âŒ INSERT ì‹¤íŒ¨:", e)
        continue

conn.commit()
print("âœ… DBì— ë‰´ìŠ¤ ë°ì´í„° ì €ì¥ ì™„ë£Œ!")

######### ì •ë¦¬ ############
if 'cursor' in locals() and cursor:
    cursor.close()
if 'conn' in locals() and conn:
    conn.close()
print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ.")